{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e069b42b",
   "metadata": {},
   "source": [
    "# Natural Language Classification\n",
    "## Ella Steen and Sharon Patta\n",
    "\n",
    "Data source: https://figshare.com/s/d83162fad67407081b32/articles/16550013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a59254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa52cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = cardiac, 1 = gastroenterological, 2 = musculoskeletal, 3 = respiratory\n",
    "\n",
    "filepath_dict = {0:   'data/Clean Transcripts/CAR0001.txt',\n",
    "                 0: 'data/Clean Transcripts/CAR0002.txt',\n",
    "                 0:   'data/Clean Transcripts/CAR0003.txt',\n",
    "                 0:   'data/Clean Transcripts/CAR0004.txt',\n",
    "                 0:   'data/Clean Transcripts/CAR0005.txt',\n",
    "                 1:   'data/Clean Transcripts/GAS0001.txt',\n",
    "                 1:   'data/Clean Transcripts/GAS0002.txt',\n",
    "                 1:   'data/Clean Transcripts/GAS0003.txt',\n",
    "                 1:   'data/Clean Transcripts/GAS0004.txt',\n",
    "                 1:   'data/Clean Transcripts/GAS0005.txt',\n",
    "                 2: 'data/Clean Transcripts/MSK0001.txt',\n",
    "                 2: 'data/Clean Transcripts/MSK0002.txt',\n",
    "                 2: 'data/Clean Transcripts/MSK0003.txt',\n",
    "                 2: 'data/Clean Transcripts/MSK0004.txt',\n",
    "                 2: 'data/Clean Transcripts/MSK0005.txt',\n",
    "                 3: 'data/Clean Transcripts/RES0001.txt',\n",
    "                 3: 'data/Clean Transcripts/RES0002.txt',\n",
    "                 3: 'data/Clean Transcripts/RES0003.txt',\n",
    "                 3: 'data/Clean Transcripts/RES0004.txt',\n",
    "                 3: 'data/Clean Transcripts/RES0005.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "stop = ['p:', 'yeah,', 'yeah', 'um,', 'um', 'uhm', 'is', 'to', 'it', 'its', \n",
    "        'a', 'ok,', 'ok', 'thank', 'just', 'no.', 'no,', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', \n",
    "    'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they',\n",
    "    'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', \n",
    "    'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as',\n",
    "    'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we',\n",
    "    'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more',\n",
    "    'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above',\n",
    "    'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any',\n",
    "    'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does',\n",
    "    'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can',\n",
    "    'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where',\n",
    "    'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't',\n",
    "    'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how',\n",
    "    'further', 'was', 'here', 'than']\n",
    "\n",
    "# Adding all of the text into dataframes with sentences and labels\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['label'] = source\n",
    "    # Filtering rows to only include patient lines\n",
    "    df = df[df['sentence'].str.startswith('P:')]\n",
    "    df['sentence'] = df['sentence'].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)])\n",
    "    )\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7550e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['sentence'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
